{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import sys\n",
    "module_path ='/home/Mingke.Chen/OwO/hh'\n",
    "\n",
    "\n",
    "\n",
    "class batch_data_generater:\n",
    "    def __init__(self):\n",
    "        self.test_file=[]\n",
    "\n",
    "        \n",
    "    def get_file_address(self,class_path,list_names):\n",
    "        image_path=[]\n",
    "        for names in list_names:\n",
    "            image_path.append(os.path.join(class_path,names))\n",
    "        return image_path\n",
    "   \n",
    "    def address_collection(self,filepath,merge=True,type='train'):\n",
    "        if type=='train':\n",
    "            self.classes=sorted(listdir(filepath[0]))\n",
    "            classes_dict={}\n",
    "            for class_index in range(len(self.classes)):\n",
    "                classes_dict.update({self.classes[class_index]:class_index})\n",
    "            self.classes_dict=classes_dict\n",
    "        \n",
    "        number_of_classes=len(self.classes)\n",
    "        number_of_locations=len(filepath)\n",
    "        storage_file=[]\n",
    "  \n",
    "        for storage_file_index in range(number_of_locations):\n",
    "            location_storage_file=[]\n",
    "            for classes_index in range(number_of_classes):\n",
    "                class_path=os.path.join(filepath[storage_file_index],self.classes[classes_index])\n",
    "                #\n",
    "                image_path=self.get_file_address(class_path,listdir(class_path))\n",
    "                location_storage_file.append(image_path)\n",
    "            storage_file.append(location_storage_file)      \n",
    "        if merge == True:\n",
    "            storage_file_reduce=[]\n",
    "            for classes_index in range(number_of_classes):\n",
    "                images_address=[]\n",
    "                for storage_file_index in range(len(storage_file)):\n",
    "                    images_address=images_address+storage_file[storage_file_index][classes_index]\n",
    "                    \n",
    "                storage_file_reduce.append(images_address)\n",
    "            storage_file=np.asarray(storage_file_reduce)\n",
    "        else:\n",
    "            storage_file=np.asarray(storage_file)\n",
    "      \n",
    "        return storage_file\n",
    "    \n",
    "    def label_Initialization(self,storage_file,framework_format='tensorflow',merge=True):\n",
    "        if framework_format=='tensorflow':\n",
    "            if merge == True:\n",
    "                storage_label=[]\n",
    "                for class_ in range(len(storage_file)):\n",
    "                    label=np.zeros([len(storage_file[class_]),len(storage_file)])\n",
    "                    for index in range(len(label)):\n",
    "                        label[index][class_]=1\n",
    "                    storage_label.append(label)\n",
    "            \n",
    "            storage_label=np.asarray(storage_label)    \n",
    "        else:\n",
    "            raise NameError('framework_format must be tensorflow')\n",
    "        return storage_label\n",
    "    \n",
    "    def batch_table_Initialization(self):\n",
    "        #get class number\n",
    "        batch_table=np.zeros(len(self.storage_file))\n",
    "        \n",
    "        for class_ in range(len(self.storage_file)):\n",
    "            batch_table[class_]=len(self.storage_file[class_])\n",
    "            \n",
    "        return batch_table\n",
    "    \n",
    "    def max_epoch_length(self,batch_size):\n",
    "    \n",
    "        epochs=np.asarray(self.batch_table)/batch_size\n",
    "        epochs=epochs*len(epochs)\n",
    "        max_epoch_index=epochs.argmax()\n",
    "        max_epoch=epochs[max_epoch_index]\n",
    "        \n",
    "        return int(max_epoch)\n",
    "        \n",
    "        \n",
    "    def init_random_data_index(self,X,y):\n",
    "        if type(X) is not np.dtype:\n",
    "            X=np.asarray(X)\n",
    "        if type(y) is not np.dtype:\n",
    "            y=np.asarray(y)\n",
    "     \n",
    "        batch_index = np.arange(0, len(X))\n",
    "        np.random.shuffle(batch_index)         \n",
    "        shuf_features = X[batch_index]\n",
    "        shuf_labels = y[batch_index]\n",
    "        \n",
    "        return shuf_features,shuf_labels\n",
    "    \n",
    "    def BatchGD_iter(self,X,y,batchsize=False,class_number=False):\n",
    "        \n",
    "        if batchsize==False:\n",
    "            batchsize=self.batchsize\n",
    "        start=0\n",
    "        recircle=False\n",
    "       \n",
    "        if class_number==False: \n",
    "            data_numbers=len(X)\n",
    "        else:\n",
    "            data_numbers=self.batch_table[class_number]\n",
    "        if batchsize > data_numbers:\n",
    "             raise NameError('batchsize is out of data samples:'+str(data_numbers))\n",
    "        shuf_features,shuf_labels=self.init_random_data_index(X,y)\n",
    "            \n",
    "        while True:\n",
    "            # shuffle labels and features\n",
    "            end=start+batchsize\n",
    "            \n",
    "            #if next batch data out of current random index\n",
    "            if end >= data_numbers:\n",
    "                remainder=end-data_numbers\n",
    "                end=data_numbers\n",
    "                recircle=True\n",
    "            \n",
    "            features_batch=shuf_features[start:end]\n",
    "            labels_batch=shuf_labels[start:end]\n",
    "          \n",
    "            start=end\n",
    "\n",
    "            #if next batch data out of current random index  init a new random index\n",
    "            if recircle == True:\n",
    "                recircle=False\n",
    "                start=0\n",
    "                shuf_features,shuf_labels=self.init_random_data_index(X,y)\n",
    "                features_batch=np.append(features_batch,shuf_features[start:remainder])\n",
    "                labels_batch=np.concatenate([labels_batch,shuf_labels[start:remainder]])\n",
    "                start=remainder\n",
    "               \n",
    "            #->random->batch->init->give other\n",
    "       \n",
    "            yield features_batch, labels_batch\n",
    "\n",
    "    def create_balance_batch_list_for_classes(self,balanced_batch_size,classes,batch_size):\n",
    "        balanced_batch_classes_size_list=[]\n",
    "        for class_ in range(classes):\n",
    "            balanced_batch_classes_size_list.append(int(balanced_batch_size))\n",
    "        remainder=batch_size%(balanced_batch_size*classes)\n",
    "        if remainder!=0:\n",
    "            for i in range(remainder):\n",
    "                balanced_batch_classes_size_list[i]+=1\n",
    "        \n",
    "        return balanced_batch_classes_size_list\n",
    "    \n",
    "    def image_address_to_image(self,address):\n",
    "        image=[]\n",
    "        for index in range(len(address)):\n",
    "            \n",
    "            image_=cv2.imread(address[index])\n",
    "            image_=image_/128\n",
    "            image.append(image_)\n",
    "        \n",
    "        return np.asarray(image)\n",
    "        \n",
    "    \n",
    "    def balance_batch_Generater(self,batch_size):\n",
    "        \n",
    "        classes=len(self.storage_label)\n",
    "        balanced_batch_size=int(batch_size/classes)\n",
    "        balanced_batch_classes_size_list=self.create_balance_batch_list_for_classes(balanced_batch_size,classes,batch_size)\n",
    "         \n",
    "        batch_storage=[]\n",
    "        for class_ in range(classes):\n",
    "            batch_storage.append(self.BatchGD_iter(self.storage_file[class_],self.storage_label[class_],\n",
    "                                                   balanced_batch_classes_size_list[class_]))\n",
    "        while True:\n",
    "            for class_ in range(classes):\n",
    "                if class_== 0:\n",
    "                    batch_data,batch_label=next(batch_storage[class_])\n",
    "                 \n",
    "                else:\n",
    "                    new_batch_data,new_batch_label=next(batch_storage[class_])\n",
    "                 \n",
    "                    batch_data=np.append(batch_data,new_batch_data,axis=0)\n",
    "                    batch_label=np.append(batch_label,new_batch_label,axis=0)\n",
    "           \n",
    "            batch_data_image=self.image_address_to_image(batch_data)\n",
    "            \n",
    "            yield batch_data_image,batch_label\n",
    "            \n",
    "    \n",
    "    def get_data_batch(self,batch_size,batch_type='balance',list_classes=False):\n",
    "        \n",
    "        if batch_type == 'balance': \n",
    "            Batch_Generater=self.balance_batch_Generater(batch_size)\n",
    "            return Batch_Generater\n",
    "     \n",
    "        \n",
    "    def filepath_Initialization(self,filepath):\n",
    "        if type(filepath) is str:\n",
    "            self.filepath=[filepath]\n",
    "        elif type(filepath) is list:\n",
    "            self.filepath=filepath\n",
    "        else:\n",
    "            raise NameError('type of filepath must be str or list')\n",
    "        train_path_list=[]\n",
    "   \n",
    "        for filepath in self.filepath:\n",
    "            train_path=filepath\n",
    "            if not os.path.exists(train_path):\n",
    "                raise NameError('No \"train\" directories under filepath' )\n",
    "            train_path_list.append(train_path)\n",
    "  \n",
    "        \n",
    "        self.train_path=train_path_list\n",
    "\n",
    "    \n",
    "    def get_batch(self,filepath,batch_size=100,batch_type='balance'):\n",
    "        #\n",
    "        self.filepath_Initialization(filepath)\n",
    "        self.storage_file=self.address_collection(self.train_path)\n",
    "        self.storage_label=self.label_Initialization(self.storage_file)\n",
    "        self.batch_table=self.batch_table_Initialization()\n",
    "        self.epoch=self.max_epoch_length(batch_size)\n",
    "\n",
    "        \n",
    "        Batch_Generater=self.get_data_batch(batch_size=batch_size,batch_type=batch_type)\n",
    "        return Batch_Generater\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
